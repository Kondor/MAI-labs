# Лабораторная работа №5

## Исследование инструментов классификации библиотеки Scikit-learn 

1. Ознакомиться с классификаторами библиотеки Scikit-learn
2. Выбрать для исследования не менее 3 классификаторов
3. Выбрать набор данных для задач классификации из открытых источников:</br>
https://tproger.ru/translations/the-best-datasets-for-machine-learning-and-data-science/ </br>
https://vc.ru/ml/150241-15-proektov-dlya-razvitiya-navykov-raboty-s-mashinnym-obucheniem </br>
https://archive.ics.uci.edu/ml/index.php </br>
https://habr.com/ru/company/edison/blog/480408/ </br>
https://www.kaggle.com/datasets/ </br>
учебные наборы библиотеки Scikit-learn
4. Выбор классификаторов и набора данных утвердить у преподавателя (не должно быть полного совпадения с выбором другого студента)
5. Для каждого классификатора определить целевой столбец и набор признаков. .
6. Подготовить данные к обучению.
7. Провести обучение и оценку моделей на сырых данных.
8. Провести предобработку данных.
9. Провести обучение и оценку моделей на очищенных данных.
10. Проанализировать результаты.
11. Результаты анализа представить в табличной и графической форме.
12. Сформулировать выводы.
13. Оформить отчет по л/р.
14. Защитить результаты работы. 

## Отчет по лабораторной работе

1. Для исследования выбрано четыре классификатора: метод k-ближайших соседей, метод опорных векторов (модель SVK), 
классификатор дерева решений, наивный байесовский метод (Гауссовский байесовский классификатор).
   - **Метод ближайших соседей (kNN - k-Nearest Neighbours)** - метод решения задач классификации и задач регрессии, 
     основанный на поиске ближайших объектов с известными значения целевой переменной.</br>
     Метод основан на предположении о том, что близким объектам в признаковом пространстве соответствуют похожие метки.
   - **Метод опорных векторов (SVM)** - это линейный алгоритм используемый в задачах классификации и регрессии. 
     Данный алгоритм имеет широкое применение на практике и может решать как линейные, так и нелинейные задачи.</br>
     Суть работы проста: алгоритм создает линию или гиперплоскость, которая разделяет данные на классы.
   - **Классификатор дерева решений (Decision Tree Classifier)** - логический алгоритм классификации, решающий задачи классификации и регрессии. 
     Представляет собой объединение логических условий в структуру дерева, состоящие из решающих правил вида «Если ..., то ...». 
     Правила автоматически генерируются в процессе обучения на обучающем множестве, 
     они формулируются практически на естественном языке деревья решений.</br>
     Цель состоит в том, чтобы создать модель, которая предсказывает значение целевой переменной, 
     изучая простые правила принятия решений, выведенные из характеристик данных. 
   - **Наивный байесовский классификатор (Naive Bayes)** — это алгоритм машинного обучения, предназначенный для 
     многоклассовой классификации данных с независимыми признаками. 
     За один проход вычисляется условная вероятность каждого признака, 
     затем применяется теорема Байеса для нахождения распределения вероятности наблюдений.</br>
     Алгоритм предполагает, что наличие какого-либо признака в классе не связано с наличием какого-либо другого признака.

2. В качестве данных выбран [wine-quality-dataset](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset). Набор данных описывает количество различных химических веществ, 
присутствующих в вине, и их влияние на его качество.

3. Обучение происходит **по всем признакам**.

4. Для анализирования просмотрим **набор данных**.
<code>print(dataset.head())</code> </br></br>
![screen_1.png](images/screen_1.png)
</br>

5. Выявим **размерность**.
<code>print('\nShape the DataSet : ', dataset.shape)</code> </br></br>
![screen_2.png](images/screen_2.png)
<br>

6. Вывод о том, понадобится ли **предобработка данных**.
<code>print(dataset.isnull().sum())</code> </br></br>
![screen_3.png](images/screen_3.png)</br>
Т.к. пустых значений нет, **предобработка данных не требуется**.
<br>

7. Выводим **описательную статистику**.</br>
**Функция describe ()** возвращает некоторые общие статистические данные данных, 
включая среднее значение, стандартное отклонение, минимальный элемент, максимальный элемент и некоторые другие детали
<code>print(dataset.describe().round(2))</code> </br></br>
![screen_4.png](images/screen_4.png)
</br>

8. Выведем **уникальные значения признака**, в соответствии с которым и будет проходить классификация.
<code>print('\nThe value quality : ', dataset['quality'].unique())</code> </br></br>
![screen_5.png](images/screen_5.png)
</br>

9. Произведем группировку **по уникальным значениям признака** и выведем средние значения.
<code>print(dataset.groupby('quality').mean().round(2))</code> </br></br>
![screen_6.png](images/screen_6.png)
</br>

10. Анализ результатов.

    Выделено 5 типов качества вина от 3 до 8 </br>
    - Лучшее качество вина - 8. </br>
    - Худшее качество вина - 3. </br>
    
    Элементы, оказывающие наибольшее влияние на качество вина: </br>
    - Alcohol (алкоголь) </br> 
    - Free sulfur dioxide (Свободный диоксид серы, двуокись) </br>
    - Total sulfur dioxide (общий диоксид серы) </br>
    
    Элементы, оказывающие наименьшее влияние на качества вина: </br>
    - Fixed acidity </br>
    - Volatile acidity </br>
    - Citric acid </br>
    - Residual sugar </br>
    - Chlorides </br>
    - Density </br>
    - PH </br>
    - Sulphates
</br>

11. Сформируем наборы данных матрицы X и вектора y. </br>
<code>X = dataset.drop(columns='quality').values</code> </br>
<code>y = dataset['quality'].values</code> </br>

12. Разделим dataset на тренировочные и тестовые данные, а затем отобразим размерность массивов.
<code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)</code> </br></br>
![screen_7.png](images/screen_7.png)
</br>

13. Рассмотрим эффективность _**метода ближайших соседей(k-NN)**_. </br>
Предоставим классификационный отчет, матрицу ошибок, метод оценки - score (показывает точность), 
метод оценки - accuracy score (показывает точность, то есть доля выборок, правильно спрогнозированных значений).</br>
![screen_8.png](images/screen_8.png)
</br></br>
**Отображение результатов графически**</br>
![screen_9.png](images/screen_9.png)
</br></br>
**Тестовые и прогнозируемые значения**</br>
![screen_10.png](images/screen_10.png)</br>
![screen_11.png](images/screen_11.png)</br>
![screen_12.png](images/screen_12.png)
</br></br>
**Гистограмма зависимости данных от признака качество (quality)**</br>
![screen_13.png](images/screen_13.png)
</br></br>

14. Рассмотрим эффективность _**метода опорных векторов (модель SVK)**_. </br>
Предоставим классификационный отчет, матрицу ошибок, метод оценки - score (показывает точность), 
метод оценки - accuracy score (показывает точность, то есть доля выборок, правильно спрогнозированных значений).</br>
![screen_14.png](images/screen_14.png)
</br></br>
**Отображение результатов графически**</br>
![screen_15.png](images/screen_15.png)
</br></br>
**Тестовые и прогнозируемые значения**</br>
![screen_16.png](images/screen_16.png)</br>
![screen_17.png](images/screen_17.png)</br>
![screen_18.png](images/screen_18.png)
</br></br>
**Гистограмма зависимости данных от признака качество (quality)**</br>
![screen_19.png](images/screen_19.png)
</br></br>

15. Рассмотрим эффективность _**классификатора дерева решений**_. </br>
Предоставим классификационный отчет, матрицу ошибок, метод оценки - score (показывает точность), 
метод оценки - accuracy score (показывает точность, то есть доля выборок, правильно спрогнозированных значений).</br>
![screen_20.png](images/screen_20.png)
</br></br>
**Отображение результатов графически**</br>
![screen_21.png](images/screen_21.png)
</br></br>
**Тестовые и прогнозируемые значения**</br>
![screen_22.png](images/screen_22.png)</br>
![screen_23.png](images/screen_23.png)</br>
![screen_24.png](images/screen_24.png)
</br></br>
**Гистограмма зависимости данных от признака качества (quality)**</br>
![screen_25.png](images/screen_25.png)
</br></br>

16. Рассмотрим эффективность _**наивного байесовского метода (рассматривается гауссовский байесовский классификатор)**_. </br>
Предоставим классификационный отчет, матрицу ошибок, метод оценки - score (показывает точность), 
метод оценки - accuracy score (показывает точность, то есть доля выборок, правильно спрогнозированных значений).</br>
![screen_26.png](images/screen_26.png)
</br></br>
**Отображение результатов графически** </br>
![screen_27.png](images/screen_27.png)
</br></br>
**Тестовые и прогнозируемые значения**</br>
![screen_28.png](images/screen_28.png)</br>
![screen_29.png](images/screen_29.png)</br>
![screen_30.png](images/screen_30.png)
</br></br>
**Гистограмма зависимости данных от признака качества (quality)**</br>
![screen_31.png](images/screen_31.png)
</br></br>

17. Результаты.

| Метод классификации               | Score train  | Score test         | Accuracy score       |
|:----------------------------------|:-------------|:-------------------|:---------------------|
| **K-nearest neighbors**           | 0.6575       | 0.4956268221574344 | 0.4956268221574344   |
| **Support Vector Classification** | 0.52875      | 0.4752186588921283 | 0.4752186588921283   |
| **Decision Tree Classifier**      | 0.96875      | 0.5860058309037901 | 0.5860058309037901   |
| **Naive Bayes**                   | 0.54375      | 0.5451895043731778 | 0.5451895043731778   |
